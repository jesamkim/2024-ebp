{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c45bf47-04fd-4394-b1ef-e5f1dd4c41c3",
   "metadata": {},
   "source": [
    "# 두 개의 RAG (OpenSearch Index) 비교 샘플 코드\n",
    "\n",
    ">이 노트북은,\n",
    "> - SageMaker Studio* **`Data Science 3.0`** kernel 및 ml.m5.large 인스턴스에서 테스트 되었습니다.\n",
    "> - SageMaker Notebook **`conda_python3`** 에서 테스트 되었습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410830b-96bd-4c80-a55a-2d62cbb83f67",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787df0f0-7fd9-47ca-a0c3-91b3037d6a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47710d-2476-4c96-92a5-d91a2f133890",
   "metadata": {},
   "source": [
    "### OpenSearch 클러스터 정보 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1263d7-019d-4a43-8fa1-4dd3cce48abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "opensearch = boto3.client('opensearch', region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e932c-909c-4c5b-81a6-bcd835a50017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [필수] 아래 OpenSearch 정보는 각자 환경에 맞게 수정 합니다.\n",
    "\n",
    "opensearch_user_id = 'raguser'\n",
    "opensearch_user_password = 'Passw0rd1!'\n",
    "\n",
    "domain_name = 'ebp-poc-all'\n",
    "opensearch_domain_endpoint = 'https://search-ebp-poc-all-uw3oqtjpbgjeg4tbb5pf3ipnpi.us-west-2.es.amazonaws.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cf3b9-26a3-4096-a6e4-4b9a39d2e82f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9a4a1-ba92-422a-96b3-c52e0b826b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "from botocore.config import Config\n",
    "import botocore \n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "retry_config = Config(\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None), # us-east-1 또는 us-west-2로 직접 지정해도 됩니다.\n",
    "    retries={\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# modelId = \"anthropic.claude-3-haiku-20240307-v1:0\"  # (Change this to try different model versions)\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "boto3_bedrock = boto3.client(service_name='bedrock-runtime',config=retry_config)\n",
    "\n",
    "#model_list = bedrock.list_foundation_models()\n",
    "#result = [(fm_list[\"modelName\"], fm_list[\"modelId\"]) for fm_list in model_list[\"modelSummaries\"] if fm_list['inferenceTypesSupported'] == ['ON_DEMAND']]\n",
    "#pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7b1ce-4407-4164-b28e-84cfde5f32f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Titan Embedding 및 LLM 인 Claude-3 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4292e3a-e33e-469d-b73d-3904919ab08b",
   "metadata": {},
   "source": [
    "### LLM 로딩 (Claude-v3 sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d7ac7-f528-4ed3-a855-cdd519ddc17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6ae65-4225-431f-a2c7-52fb22e814ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_text = BedrockChat(\n",
    "    model_id=modelId,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    model_kwargs={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\" : 0,\n",
    "        \"top_k\": 350,\n",
    "        \"top_p\": 0.999\n",
    "    }\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9ad47-56b6-427d-84a6-4e792bf4f6f9",
   "metadata": {},
   "source": [
    "### Embedding 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afde2a-097b-4a00-82e4-e7bab6e2a4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "llm_emb = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    # model_id=\"cohere.embed-multilingual-v3\"\n",
    "    model_id=\"amazon.titan-embed-g1-text-02\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f25b2-8b20-4b57-bc66-bf2b6004cc1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8090d-f864-4419-bf20-8135914c0876",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. OpenSearch 벡터 Index 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c5796-a418-4505-ba28-0ca33c3fa9f8",
   "metadata": {},
   "source": [
    "### 오픈 서치 인덱스 유무에 따라 삭제\n",
    "오픈 서치에 해당 인덱스가 존재하면, 삭제 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441a96e-6a2b-42d2-8b27-db78d5dd97d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "http_auth = (opensearch_user_id, opensearch_user_password)\n",
    "os_client = OpenSearch(\n",
    "            hosts=[\n",
    "                {'host': opensearch_domain_endpoint.replace(\"https://\", \"\"),\n",
    "                 'port': 443\n",
    "                }\n",
    "            ],\n",
    "            http_auth=http_auth, # Master username, Master password,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac0292-f3fc-4ef7-a00d-becee90f0dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Project-1을 위한 index 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bec59-9f17-4250-b133-a82767d79657",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name_1 = \"project-1-index\"\n",
    "exists = os_client.indices.exists(index_name_1)\n",
    "\n",
    "if exists:\n",
    "    os_client.indices.delete(index=index_name_1)\n",
    "    print(\"Index is deleted\")\n",
    "else:\n",
    "    print(\"Index does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad62cb-22ff-4031-b301-0baec1e5608d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## metadata, text, vector_field 의 네이밍은 langchain에서 지정된 이름\n",
    "### model에 따라 dimension 사이즈 변경 필요 (Titan : 1536, Cohere : 1024)\n",
    "import json\n",
    "\n",
    "with open('index_body_simple.json', 'r') as f:\n",
    "    index_body = json.load(f)\n",
    "\n",
    "print(json.dumps(index_body, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66746526-4e79-4e41-a985-79697b5bb8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_client.indices.create(index_name_1, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4971b6-777d-48a1-82dd-668a38e48587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "vector_db_1 = OpenSearchVectorSearch(\n",
    "    index_name=index_name_1,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50730a3e-0881-48d6-a77e-f49921ce06f1",
   "metadata": {},
   "source": [
    "### Project-2를 위한 index 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391645e0-0172-46b0-a687-fb242291649e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name_2 = \"project-2-index\"\n",
    "exists = os_client.indices.exists(index_name_2)\n",
    "\n",
    "if exists:\n",
    "    os_client.indices.delete(index=index_name_2)\n",
    "    print(\"Index is deleted\")\n",
    "else:\n",
    "    print(\"Index does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae6036-19f4-43a0-a438-698b63120fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## metadata, text, vector_field 의 네이밍은 langchain에서 지정된 이름\n",
    "### model에 따라 dimension 사이즈 변경 필요 (Titan : 1536, Cohere : 1024)\n",
    "import json\n",
    "\n",
    "with open('index_body_simple.json', 'r') as f:\n",
    "    index_body = json.load(f)\n",
    "\n",
    "print(json.dumps(index_body, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d51172-6f4d-4471-b50f-746d02cf2753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_client.indices.create(index_name_2, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf8250-b940-4dfb-a3db-54fbf0524eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "vector_db_2 = OpenSearchVectorSearch(\n",
    "    index_name=index_name_2,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7070c1-8640-40cb-969d-1bc1a413d3f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. 데이터 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5321ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyPDF 설치\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "# PyPDF 임포트\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# from llmsherpa.readers import LayoutPDFReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054afa5-02db-407f-9960-19ce60349992",
   "metadata": {},
   "source": [
    "#### Project-1 에 대한 PDF 문서 폴더 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c614e-aa36-499b-90e3-e29ad81c853e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "# Project-1 문서 폴더\n",
    "data_path_1 = './data/project-1/*'\n",
    "pdf_list_1 = glob.glob(data_path_1)\n",
    "pdf_list_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a6c57-54b1-4bc3-9f2f-434bf48c6324",
   "metadata": {},
   "source": [
    "#### Project-2에 대한 PDF 문서 폴더 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765c485-b833-4fdb-bd8c-7be6ecf7248c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Project-2 문서 폴더\n",
    "data_path_2 = './data/project-2/*'\n",
    "pdf_list_2 = glob.glob(data_path_2)\n",
    "pdf_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552675a-8803-40b4-a637-30a9b498ecfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import  Manager\n",
    "\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85823bc-5171-49fb-a06c-d10ad5672f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prune_text(text, current_pdf_file):\n",
    "\n",
    "    def replace_cid(match):\n",
    "        print(f\"Please check PDF file {current_pdf_file} : {match}\")\n",
    "        ascii_num = int(match.group(1))\n",
    "        try:\n",
    "            return chr(ascii_num)\n",
    "        except:\n",
    "            return ''  # In case of conversion failure, return empty string\n",
    "\n",
    "    # Regular expression to find all (cid:x) patterns\n",
    "    cid_pattern = re.compile(r'\\(cid:(\\d+)\\)')\n",
    "    pruned_text = re.sub(cid_pattern, replace_cid, text)\n",
    "    return pruned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887b6a5-4c82-4123-b152-3e990357fb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def read_pdf(param):\n",
    "    vector_db = param[0]\n",
    "    current_pdf_file = param[1]\n",
    "    print(f\"current_pdf_file : {current_pdf_file}\")\n",
    "    docs = []\n",
    "    source_name = current_pdf_file.split('/')[-1]\n",
    "    type_name = source_name.split('_')[0]\n",
    "\n",
    "    loader = PyPDFLoader(current_pdf_file)\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    for page_number, page in enumerate(pages, start=1):\n",
    "        page_text = page.page_content\n",
    "        if page_text:\n",
    "            pruned_text = prune_text(page_text, current_pdf_file)\n",
    "        else:\n",
    "            pruned_text = \"\"\n",
    "        if len(pruned_text) >= 20:  ## 임의로 20 이상인 sentence만 뽑도록 함\n",
    "            chunk = Document(\n",
    "                page_content=pruned_text.replace('\\n',' '),\n",
    "                metadata={\n",
    "                    \"source\" : source_name,\n",
    "                    \"type\": type_name,\n",
    "                    \"timestamp\": datetime.now()\n",
    "                }\n",
    "            )\n",
    "            #print(f\"chunk : {chunk}\")\n",
    "            vector_db.add_documents([chunk])\n",
    "    #         docs.append(chunk)\n",
    "    # if len(docs) > 0 :\n",
    "    #     vector_db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9077509-3bae-46e9-a90d-1849b361edd6",
   "metadata": {},
   "source": [
    "### Project-1 을 위한 OpenSearch 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f90ea-85b1-4066-8260-42bf3df14cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "result_dict = manager.dict()\n",
    "\n",
    "# ml.m5.xlarge에서 multiprocessing으로 동작 확인\n",
    "param = [(vector_db_1, current_pdf_file)for current_pdf_file in pdf_list_1]\n",
    "\n",
    "num_processes = len(pdf_list_1)%os.cpu_count()\n",
    "\n",
    "if num_processes == 0 :\n",
    "    num_processes = os.cpu_count() - 1\n",
    "\n",
    "print(f\"num of process : {num_processes}\")\n",
    "\n",
    "with ThreadPool(processes=num_processes) as pool:\n",
    "    pool.map(read_pdf, param)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae62975-2e46-44e7-97e4-c14c2bfa632f",
   "metadata": {},
   "source": [
    "### Project-1 을 위한 OpenSearch 인덱스 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14827f89-c54b-440d-ab7f-5bb22eefc313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_info_1 = os_client.indices.get(index=index_name_1)\n",
    "print(json.dumps(index_info_1, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00a113-023b-4f2f-a7b4-f8a0a20fc6fc",
   "metadata": {},
   "source": [
    "### Project-2 를 위한 OpenSearch 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7d2e9-1e32-4084-b4a3-432d67e4b658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "result_dict = manager.dict()\n",
    "\n",
    "# ml.m5.xlarge에서 multiprocessing으로 동작 확인\n",
    "param = [(vector_db_2, current_pdf_file)for current_pdf_file in pdf_list_2]\n",
    "\n",
    "num_processes = len(pdf_list_2)%os.cpu_count()\n",
    "\n",
    "if num_processes == 0 :\n",
    "    num_processes = os.cpu_count() - 1\n",
    "\n",
    "print(f\"num of process : {num_processes}\")\n",
    "\n",
    "with ThreadPool(processes=num_processes) as pool:\n",
    "    pool.map(read_pdf, param)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924f875-460f-48e5-9d80-4787b6e84626",
   "metadata": {},
   "source": [
    "### Project-2 를 위한 OpenSearch 인덱스 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15cf873-2f94-4f27-96dd-2f33ac8e28dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_info_2 = os_client.indices.get(index=index_name_2)\n",
    "print(json.dumps(index_info_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dade762-3229-4720-b951-d3de3237e4d0",
   "metadata": {},
   "source": [
    "## 5. Hybrid Search 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305c9b8-4c14-4e81-b741-91f59506d7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearch_dsl import Search\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# from utils.rag import run_RetrievalQA, show_context_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9bb64-96d8-429a-87f7-c346acc625d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import BaseRetriever\n",
    "from typing import Any, Dict, List, Optional, List, Tuple\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "\n",
    "# lexical(keyword) search based (using Amazon OpenSearch)\n",
    "class OpenSearchLexicalSearchRetriever(BaseRetriever):\n",
    "    os_client: Any\n",
    "    index_name: str\n",
    "    k = 3\n",
    "    filter = []\n",
    "\n",
    "    def normalize_search_results(self, search_results):\n",
    "        hits = (search_results[\"hits\"][\"hits\"])\n",
    "        max_score = float(search_results[\"hits\"][\"max_score\"])\n",
    "        for hit in hits:\n",
    "            hit[\"_score\"] = float(hit[\"_score\"]) / max_score\n",
    "        search_results[\"hits\"][\"max_score\"] = hits[0][\"_score\"]\n",
    "        search_results[\"hits\"][\"hits\"] = hits\n",
    "        return search_results\n",
    "\n",
    "    def update_search_params(self, **kwargs):\n",
    "        self.k = kwargs.get(\"k\", 3)\n",
    "        self.filter = kwargs.get(\"filter\", [])\n",
    "        self.index_name = kwargs.get(\"index_name\", self.index_name)\n",
    "\n",
    "    def _reset_search_params(self, ):\n",
    "        self.k = 3\n",
    "        self.filter = []\n",
    "        \n",
    "    def query_lexical(self, query, filter=[], k=5):\n",
    "        QUERY_TEMPLATE = {\n",
    "            \"size\": k,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\n",
    "                            \"match\": {\n",
    "                                \"text\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"operator\":  \"or\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"filter\": filter\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if len(filter) > 0:\n",
    "            QUERY_TEMPLATE[\"query\"][\"bool\"][\"filter\"].extend(filter)\n",
    "            \n",
    "        return QUERY_TEMPLATE\n",
    "    \n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:\n",
    "        \n",
    "        query = self.query_lexical(\n",
    "            query=query,\n",
    "            filter=self.filter,\n",
    "            k=self.k\n",
    "        )\n",
    "\n",
    "        # print (\"lexical search query: \")\n",
    "        # print(query)\n",
    "        \n",
    "        search_results = self.os_client.search(\n",
    "            body=query,\n",
    "            index=self.index_name\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        if search_results[\"hits\"][\"hits\"]:\n",
    "            search_results = self.normalize_search_results(search_results)\n",
    "            for res in search_results[\"hits\"][\"hits\"]:\n",
    "\n",
    "                metadata = res[\"_source\"][\"metadata\"]\n",
    "                metadata[\"id\"] = res[\"_id\"]\n",
    "\n",
    "                doc = Document(\n",
    "                    page_content=res[\"_source\"][\"text\"],\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                results.append((doc))\n",
    "\n",
    "        self._reset_search_params()\n",
    "\n",
    "        return results[:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9f483-0e50-4c5e-ae90-15a0f91594c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\\n\\nHuman: Use the following pieces of context to provide a concise answer to the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\\n\\nAssistant:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb9f8d-1791-4993-938f-bf17fde60aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = load_qa_chain(\n",
    "    llm=llm_text,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=PROMPT,\n",
    "    verbose=False  # LLM 답변 과정을 출력하려면 True로 변경 합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ee5b9-fd2d-42a5-9979-940c92e2979e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project-1, Project-2 인덱스에 각각 요청할 공통 쿼리\n",
    "\n",
    "query = \"1차에너지 공급 연평균 성장률에 대해서 상세히 알려주세요.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd25e7d-b702-4dfd-98b5-0b1a7e56b8ff",
   "metadata": {},
   "source": [
    "## 6. Project-1에 대한 쿼리 (하이브리드 서치 : Sementic + Lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb31c3-69d3-4ad5-9801-ea51b3dbe266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boolean_filter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e583488-d82e-47af-889e-820bdbac208c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = index_name_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6db70-bad6-457c-8884-2121de002397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_semantic_retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"boolean_filter\": boolean_filter\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44c1e1-4ced-4c79-b70b-1ee02bfa8616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_lexical_retriever = OpenSearchLexicalSearchRetriever(\n",
    "    os_client=os_client,\n",
    "    index_name=index_name,\n",
    "    k=3,\n",
    "    filter=boolean_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72b2e8-c0d1-4aee-9307-497ce63b73b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[opensearch_lexical_retriever, opensearch_semantic_retriever],\n",
    "    weights=[0.5, 0.5],\n",
    "    c=100,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9cb74-c060-4093-9b59-cbf17b8a41c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_1 = chain.invoke(\n",
    "    {\n",
    "        \"input_documents\": ensemble_retriever.get_relevant_documents(query), \n",
    "        \"question\": query\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"##############################\")\n",
    "print(\"query: \\n\", query)\n",
    "print(\"answer: \\n\", answer_1['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15ce72-cb98-4592-916d-ad10b5444288",
   "metadata": {},
   "source": [
    "## 7. Project-2에 대한 쿼리 (하이브리드 서치 : Sementic + Lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8242a-e87b-4d16-a1ca-b3e505e73d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boolean_filter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0066d9b4-0d06-417e-9d39-f491d95637de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = index_name_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3feb4e-15e9-4014-b062-c2b9664cd651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_semantic_retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"boolean_filter\": boolean_filter\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8f62b-faaf-4026-8178-794c243448ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_lexical_retriever = OpenSearchLexicalSearchRetriever(\n",
    "    os_client=os_client,\n",
    "    index_name=index_name,\n",
    "    k=3,\n",
    "    filter=boolean_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bdfd2-8cf5-4c3d-95ee-62a2bae6edce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[opensearch_lexical_retriever, opensearch_semantic_retriever],\n",
    "    weights=[0.5, 0.5],\n",
    "    c=100,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c410a-c234-4a4b-a103-41de3040ac31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_2 = chain.invoke(\n",
    "    {\n",
    "        \"input_documents\": ensemble_retriever.get_relevant_documents(query), \n",
    "        \"question\": query\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"##############################\")\n",
    "print(\"query: \\n\", query)\n",
    "print(\"answer: \\n\", answer_2['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7feb218-50c5-47da-977c-aec556eb414b",
   "metadata": {},
   "source": [
    "## 8. Project-1과 Project-2의 답변을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef99f3b-31be-4fca-97f6-a3d9c1ebbc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_1 = answer_1['output_text']\n",
    "context_2 = answer_2['output_text']\n",
    "\n",
    "# 답변 비교 프롬프트 예시\n",
    "comp_prompt = f\"\"\"\n",
    "다음 {context_1}과 {context_2}를 비교 합니다. \n",
    "답변은 최대한 상세히 합니다. 모르는 내용을 말하지 않습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf92b7b-bc13-4a5c-b767-28f3030d12a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "def get_text_response(input_content):\n",
    "    llm = BedrockChat(\n",
    "        credentials_profile_name=os.environ.get(\"BWB_PROFILE_NAME\"),\n",
    "        region_name=os.environ.get(\"BWB_REGION_NAME\"),\n",
    "        endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\"),\n",
    "        model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        model_kwargs={\n",
    "            \"max_tokens\": 4096,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 0.01,\n",
    "            \"top_k\": 0,\n",
    "        }\n",
    "    )\n",
    "    return llm.predict(input_content)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = comp_prompt\n",
    "    response_content = get_text_response(input_content=input_text)\n",
    "    print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cbe38-5855-45c1-9fba-155d7dd1a5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b55996-4fec-4608-8131-4f8e45984740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ae463-9a33-47d3-8e07-b1ffe9b5b6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
